{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P06.TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0cwBirO2caY9MXn94Svlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcstllns/DeepLearning/blob/main/P06_TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6rtaWiarkIm"
      },
      "source": [
        "# Red convolucional preentrenada\n",
        "\n",
        "En esta práctica vamos a analizar otro de los ficheros pregargados que hay en Keras, un conjunto de imágenes de ropa llamdo fashion-mnist. Tienes una descripción de los datos en este [enlace](https://keras.io/api/datasets/fashion_mnist/).\n",
        "\n",
        "Las imágenes pertenecen a 10 categorías de ropa, clasificadas con un número del 0 al 9. Un ejemplo de la imágenes:\n",
        "![Conjunto MNIST](https://www.tensorflow.org/tutorials/keras/classification_files/output_oZTImqg_CaW1_0.png?hl=es-419)\n",
        "\n",
        "Para analizar estos datos vamos a usar una red preentrenada la VGG16, es una red del 2015 y aunque no es de las más potentes comparada con las más modernas funciona bastante bien. Tiene unos 15 millones de parámetros y mezcla bloques con capas de convolución y pooling. Puedes encontrar más información en la página de keras dedicada a la red ([enlace](https://keras.io/api/applications/vgg/)).\n",
        "\n",
        "Los datos son similares a mnist, imágenes de 28x28 en escala de grises y VGG16 solo acepta imágenes de al menos 32x32 y en formato RGB por lo que habrá que hacer un preprocesamiento. Como la ejecución es muy demandante vamos a crear un conjunto reducido de solo 100 imágenes para hacer las pruebas y luego el alumno puede intentar ejecutarlo con todo el set completo.\n",
        "\n",
        "Vamos a cargar solo parte de la red, las capas inferiores dedicadas a la extracción de rasgos y luego añadiremos nuestras capas que sí vamos a entrenar para que haga bien la tarea de clasificación.\n",
        "\n",
        "Muchas de las cosas que se utilizan están ya vistas en otras prácticas con lo que aparecerán solo mencionadas.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC3ROj-7LpNW"
      },
      "source": [
        "# Importamos librerías\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhc0ezBrrjO_"
      },
      "source": [
        "# definimos la función para visualizar la historia\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.plot(hist['epoch'], hist['loss'],'r--',\n",
        "           label='Training Error')\n",
        "  plt.plot(hist['epoch'], hist['val_loss'],'b',\n",
        "           label = 'Validation Error')\n",
        "  # plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qqWJ0xJ9w-B"
      },
      "source": [
        "# importamos los datos desde keras\n",
        "\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
        "\n",
        "# visualizamos la imagen 8\n",
        "plt.imshow(x_train[8])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4doiGrt905c"
      },
      "source": [
        "# Preprocesamiento -------------------\n",
        "\n",
        "# seleccionamos 100 imagenes para probar\n",
        "idx = np.random.randint(60000, size=100)\n",
        "x_train_small = x_train[idx,:,:]\n",
        "y_train_small = y_train[idx]\n",
        "\n",
        "# expandimos las imagenes a 32x32 y con una dimension más que va a ser el color\n",
        "x_train_small = np.expand_dims(x_train_small, axis=-1)\n",
        "x_train_small = tf.image.resize(x_train_small, [32,32]) # if we want to resize\n",
        "\n",
        "# Pasamos la escala de grises a RGB\n",
        "x_train_small=tf.image.grayscale_to_rgb(x_train_small)\n",
        "\n",
        "# Normalizamos para que los valores vayan de 0 a 1\n",
        "x_train_small = x_train_small/255.\n",
        "\n",
        "# comprobamos que las dimensiones son correctas\n",
        "print(x_train_small.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BtNQpJ-_R4M"
      },
      "source": [
        "Ahora se carga la red preentrenada, es tan sencillo como el siguiente código:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pre_trained_model = VGG16(input_shape = (32, 32, 3),\n",
        "                          include_top = False,\n",
        "                          weights = 'imagenet')\n",
        "```\n",
        "Le estamos indicando que vamos a introducir imágenes de 32x32x3 y que solo incluya las capas inferiores. El último parámetro especifica que se utilice la confifuración dada con imagenet.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5aKfgm8_CYJ"
      },
      "source": [
        "pre_trained_model = VGG16(input_shape = (32, 32, 3),\n",
        "                          include_top = False,\n",
        "                          weights = 'imagenet')\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw7Tnz8TALHk"
      },
      "source": [
        "Fíjate que la red contiene casi 15 millones de parámetros, ahora le tenemos que decir que son no entrenables, es decir, que no cambien los valores que tienen ya los pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz6IwkB5AVhe"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1h8Qo1kAYZZ"
      },
      "source": [
        "Mira como Trainable params ha pasado de 14 millones a 0, ahora nada de esta red se va a modificar.\n",
        "\n",
        "Tenemos que añadir las capas que se van a encargar de la clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EogjWxR_An8N"
      },
      "source": [
        "# creamos nuestro modelo incluyendo el pre_trained\n",
        "\n",
        "model = Sequential()\n",
        "model.add(pre_trained_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBxiwjvmAwAS"
      },
      "source": [
        "# compilamos con los parametros habituales\n",
        "\n",
        "model.compile(\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2-VaD68A2k-"
      },
      "source": [
        "# Aprendizaje\n",
        "\n",
        "# FIT     ----------------------------------------------------------------\n",
        "start = time.time()\n",
        "history = model.fit(x_train_small, y_train_small,\n",
        "              batch_size=10,\n",
        "              epochs=30,\n",
        "              validation_split = 0.2,\n",
        "              verbose=1)\n",
        "end = time.time()\n",
        "print('Tiempo de ejecución:', end - start)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNzdDlfKA-5i"
      },
      "source": [
        "# Evaluacion\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_train_small, y_train_small)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XirSO5SWtWl"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "\n",
        "Ajusta los parametros de clasificacion de la red con el grupo de imagenes pequeño x_train_small y cuando creas que funciona razonablemente bien pasa a calcular la red con todos los datos\n",
        "\n",
        "Fíjate que no hemos preprocesado ni los datos de x_test ni ninguno de los que pertenecen al conjunto de test\n",
        "\n",
        "Cuando tengas tu red lista sube los comentarios y la parte del codigo que consideres interesante a moodle\n",
        "\n"
      ]
    }
  ]
}