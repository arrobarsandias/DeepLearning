{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo de data Augmentation"
      ],
      "metadata": {
        "id": "L8vpxRjaHm33"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPkLy98yXuwG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import plot_model\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definimos la funci칩n para visualizar la historia\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.plot(hist['epoch'], hist['loss'],'r--',\n",
        "           label='Training Error')\n",
        "  # plt.plot(hist['epoch'], hist['val_loss'],'b',\n",
        "  #          label = 'Validation Error')\n",
        "  # plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IDWcJEUIJpvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos datos y visualizamos una imagen\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# visualizamos la imagen 8\n",
        "plt.imshow(x_train[8])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yUsDVdxXdyCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.ndim)\n",
        "print(x_train.shape)\n",
        "print(y_train.ndim)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "PmQq5PoTd5wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# guardamos las dimensiones en variables para hacer la red mas generica\n",
        "# y reutilizable\n",
        "\n",
        "ntrain = x_train.shape[0]\n",
        "ntest  = x_test.shape[0]\n",
        "dimf = x_train.shape[1]\n",
        "dimc = x_train.shape[2]\n",
        "\n",
        "print(\"dimensiones: \", ntrain, ntest, dimf, dimc)"
      ],
      "metadata": {
        "id": "7Yz3OBYmeOLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizamos los pixeles\n",
        "x_train = x_train.astype('float32')/255.\n",
        "\n",
        "# La funcion ImageDatagenerator solo acepta estructuras 3D, por eso introducimos una dimension mas\n",
        "x_train = x_train.reshape(ntrain, dimf, dimc, 1)\n",
        "\n",
        "# one hot\n",
        "y_train = to_categorical(y_train, 10)"
      ],
      "metadata": {
        "id": "vdNPirRueIB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "n88YXrx1ell9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se definen que tipo de transformaciones queremos realizar de las im치genes\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=15,width_shift_range=0.2,height_shift_range=0.2,\n",
        "                             shear_range=0.15,zoom_range=[0.5,2],validation_split=0.2)\n",
        "datagen.fit(x_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "OH_7DBSIewgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un ejemplo que genera 5 im치genes y las visualizamos\n",
        "\n",
        "it = datagen.flow(x_train, y_train, batch_size=5)\n",
        "batch_images, batch_labels = next(it)\n",
        "\n",
        "for i in range(5):\n",
        "  plt.imshow(batch_images[i])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "KBw0Ht1NIwIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un modelo convolucional de ejemplo\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(32, (5,5), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64, (5,5), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# summarize layers\n",
        "print(model.summary())\n",
        "\n",
        "# plot graph\n",
        "plot_model(model)"
      ],
      "metadata": {
        "id": "A_sVAHbBiW5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ojo, las convolucionales pueden ser muy lentas entrenando\n",
        "# Prueba a seleccionar solo un conjunto de las imagenes y entrenar la red con ellas\n",
        "\n",
        "history = model.fit(\n",
        "              datagen.flow(x_train, y_train, batch_size=32),\n",
        "              epochs=1,\n",
        "              verbose=1)                # para que no ocupe toda la pantalla\n"
      ],
      "metadata": {
        "id": "BcYLoWwRjGzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluacion\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_train, y_train)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "fnGXpXYwKEWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "K9PFTb3aML-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea\n",
        "\n",
        "Prueba a integrar la estrategia de data augmentation con una red preentrenada.\n",
        "\n",
        "Prueba a crear redes convolucionales que procesen las im치genes en paralelo.\n",
        "\n",
        "Prueba a aplicar la red al conjunto de datos de CIFAR10 incluida en Keras"
      ],
      "metadata": {
        "id": "4so1cCIbKGF5"
      }
    }
  ]
}