{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Los datos provienen de un test de Autoconcepto que mide 5 componentes distintos. Además se han incluido algunas variables que se pueden usar como criterio. La lista con todas las variables está disponible en **listado de preguntas FINAL.xlsx**\n",
        "\n",
        "\n",
        "El objetivo es ser capaz de predecir los ingresos mensuales (**A2**) utilizando la información de los componentes."
      ],
      "metadata": {
        "id": "n1MyoVJCFJMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzhUubxX8pte"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# funciones que nos van a ayudar\n",
        "\n",
        "# normaliza un conjunto de datos\n",
        "def norm(x, st):\n",
        "    return((x - st['mean'])/st['std'])\n",
        "\n",
        "# grafico de la historia    \n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error')\n",
        "  plt.plot(hist['epoch'], hist['loss'],'r--',\n",
        "           label='Training Error')\n",
        "  # plt.plot(hist['epoch'], hist['mse'],'b',\n",
        "  #          label = 'mse')\n",
        "  #plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show() # un €"
      ],
      "metadata": {
        "id": "EMssOABDsCm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/mcstllns/DeepLearning/main/datos%20para%20P07/Datos%20AF%20final.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "O58C42hp9AUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "# print(df.head())\n",
        "# print(df.columns)"
      ],
      "metadata": {
        "id": "u8aMQhar9XV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se preparan los datos para ser metidos en la red\n",
        "\n",
        "X = df.iloc[:,np.r_[df.columns.get_loc(\"A01.10\"):df.columns.get_loc(\"S04.14\")+1, df.columns.get_loc(\"A2\")]]\n",
        "X = X.dropna()\n",
        "\n",
        "\n",
        "# Esta parte separa en train y test, pero en nuestro caso no tiene sentido \n",
        "# porque el objetivo es descriptivo, no predictivo\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X.iloc[:,0:50], X.iloc[:,50], test_size=0.20)\n",
        "\n",
        "x = X.iloc[:,0:50]\n",
        "y = X.iloc[:,50]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LZLhmZie-LFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se normaliza x e y \n",
        "\n",
        "x_stats = x.describe().transpose()\n",
        "y_stats = y.describe().transpose()\n",
        "\n",
        "x_norm = norm(x, x_stats)\n",
        "y_norm = norm(y, y_stats)"
      ],
      "metadata": {
        "id": "qkpGu3aQ1OaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_norm.shape)\n",
        "print(y_norm.shape)\n"
      ],
      "metadata": {
        "id": "e9OOjKNnET5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construcción del modelo\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation = 'relu', input_shape=[( len(x.keys()) )]))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer = Adam(learning_rate = 0.001),\n",
        "              metrics = ['mse','mae'])"
      ],
      "metadata": {
        "id": "2zZgwrUDpyWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo que tiene más sentido es normalizar x pero utilizar y en su escala original\n",
        "\n",
        "history = model.fit(x_norm, y,\n",
        "                    epochs = 500,\n",
        "                    batch_size = 25,\n",
        "                    verbose = 1) "
      ],
      "metadata": {
        "id": "O9vOkRNOqy4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "FcoEGJoDqUF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_norm, y)"
      ],
      "metadata": {
        "id": "MLes4hru18Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como las variables son cuantitativas un grafico de dispersion podría estar perfecto\n",
        "\n",
        "yp = model.predict(x_norm)\n",
        "\n",
        "\n",
        "df = pd.DataFrame({'y': y, 'yp': yp.flatten()})\n",
        "df.plot.scatter(x='y', y='yp')\n",
        "plt.xlim([0,5000])\n",
        "plt.ylim([0,5000])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LC-XsQ_b2LCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea\n",
        "\n",
        "Utilice una arquitectura funcional para separar los componentes en líneas de procesamiento. Interprete los resultados.\n",
        "\n",
        "Utilice los datos para predecir otras variables relevantes del fichero.\n"
      ],
      "metadata": {
        "id": "DDVMfMkfFAZQ"
      }
    }
  ]
}